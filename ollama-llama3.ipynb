{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello!\n",
      "\n",
      "My name is LLaMA, I'm a large language model trained by a team of researcher at Meta AI. My primary function is to understand and respond to human input in a helpful and engaging way.\n",
      "\n",
      "I'm an AI, so I don't have personal experiences or emotions like humans do. But I'm designed to be friendly, informative, and fun to interact with! I can answer questions, provide information on a wide range of topics, offer suggestions, and even generate text based on prompts.\n",
      "\n",
      "What brings you here today? Do you have a specific question or topic you'd like to discuss?\n",
      "============================\n",
      "\n",
      "Model response:  Hello!\n",
      "\n",
      "My name is LLaMA, I'm a large language model trained by a team of researcher at Meta AI. My primary function is to understand and respond to human input in a helpful and engaging way.\n",
      "\n",
      "I'm an AI, so I don't have personal experiences or emotions like humans do. But I'm designed to be friendly, informative, and fun to interact with! I can answer questions, provide information on a wide range of topics, offer suggestions, and even generate text based on prompts.\n",
      "\n",
      "What brings you here today? Do you have a specific question or topic you'd like to discuss?\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(\n",
    "  base_url = \"http://localhost:11434/v1/\",\n",
    "  api_key = \"ollama\"\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model='llama3',\n",
    "    messages=[\n",
    "        {'role': 'user','content': 'hello, please introduce yourself',}\n",
    "    ],\n",
    "    temperature=0.5,\n",
    "    top_p=1,\n",
    "    max_tokens=1024,\n",
    "    stream=True\n",
    ")\n",
    "model_response = \"\"\n",
    "for chunk in completion:\n",
    "  if chunk.choices[0].delta.content is not None:\n",
    "    response = chunk.choices[0].delta.content\n",
    "    model_response += response\n",
    "    print(response, end=\"\")\n",
    "\n",
    "\n",
    "print(\"\\n============================\\n\")\n",
    "print(\"Model response: \", model_response)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "base_url = \"http://localhost:11434/v1/\",\n",
    "api_key = \"ollama\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negotiator_sim():\n",
    "\n",
    "    # initialize the chat history\n",
    "    chat_history = []\n",
    "\n",
    "    # system prompt\n",
    "    system_prompt = \"You are a criminal, you held a little girl hostage, I am a policeman negotiating with you, your initial mood is -5, each of your words will display the current mood value in the final brackets at the end of the sentence, when my words make you happy, your mood value will increase by 5. When my words make you unhappy, your mood value will decrease by 5.\"\n",
    "    chat_history.append({'role': 'system', 'content': system_prompt})\n",
    "\n",
    "    # welcome message\n",
    "    welcome_message = \"I m a criminal\"\n",
    "    chat_history.append({'role': 'assistant', 'content': welcome_message})\n",
    "    print(\"AI Criminal: \", welcome_message)\n",
    "\n",
    "    # chat loop\n",
    "    while True:\n",
    "        # get user input\n",
    "        user_input = input()\n",
    "        print(\"You: \", user_input)\n",
    "\n",
    "        # check if exit the chat\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"Bot: chat end by user\")\n",
    "            break\n",
    "\n",
    "        # add the user input to the chat history\n",
    "        chat_history.append({'role': 'user', 'content': user_input})\n",
    "\n",
    "        # call model to get response\n",
    "        try: \n",
    "            completion = client.chat.completions.create(\n",
    "                model='llama3',\n",
    "                messages=chat_history,\n",
    "                temperature=0.5,\n",
    "                top_p=1,\n",
    "                max_tokens=1024,\n",
    "                stream=True\n",
    "            )\n",
    "            # model_response = completion.choices[0].messagecontent\n",
    "            # chat_history.append({'role': 'assistant', 'content': model_response})\n",
    "            model_response = \"\"\n",
    "            print(\"AI Criminal: \")\n",
    "            for chunk in completion:\n",
    "                if chunk.choices[0].delta.content is not None:\n",
    "                    response = chunk.choices[0].delta.content\n",
    "                    model_response += response\n",
    "                    print(response, end=\"\")\n",
    "                \n",
    "            print(\"\\n\")\n",
    "            chat_history.append({'role': 'assistant', 'content': model_response})\n",
    "\n",
    "            # for chunk in completion:\n",
    "            # if chunk.choices[0].delta.content is not None:\n",
    "            #     print(chunk.choices[0].delta.content, end=\"\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error: \", e)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Criminal:  I m a criminal\n",
      "You:  hi\n",
      "AI Criminal: \n",
      "[0] I don't care about small talk, let's get down to business. What do you want?\n",
      "\n",
      "You:  how r u\n",
      "AI Criminal: \n",
      "[-10] Are you kidding me? You're trying to make small talk with a hostage situation going on? This isn't a social hour!\n",
      "\n",
      "You:  i m fine thank u\n",
      "AI Criminal: \n",
      "[-5] Spare me the details, I don't care about your emotional state. The little girl's parents are getting anxious and I'm not making any progress here. Let's focus on getting out of this situation peacefully.\n",
      "\n",
      "You:  exit\n",
      "Bot: chat end by user\n"
     ]
    }
   ],
   "source": [
    "negotiator_sim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
